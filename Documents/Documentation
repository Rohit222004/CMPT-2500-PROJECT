# **Deep Explanation of the Project Code**  

This document provides an in-depth explanation of the primary scripts and design decisions in the **Days on Market Predictor for Vehicle Sales Optimization** project. The project is modularized into components for data preprocessing, model training, prediction (both batch and via a REST API), evaluation, and model persistence. This design adheres to best practices in MLOps, ensuring maintainability and extensibility.

---

## 1. **`preprocess.py`**  

### **Purpose**
Handles data cleaning, feature engineering, and preliminary visualizations to convert raw CSV data into a format suitable for modeling.

### **DataPreprocessor Class**

- **Attributes:**
  - `file_path (str)`: Path to the raw CSV data file.  
  - `df (pd.DataFrame)`: The dataset loaded from CSV.  
  
- **Methods:**
  - **`load_data()`**  
    - Reads the CSV file using `pandas.read_csv`.  
    - Prints a preview (head, info, describe, shape) of the dataset.  
    - Returns the loaded DataFrame.  

  - **`preprocess_data()`**  
    - Checks for and logs duplicate rows.  
    - Selects relevant columns.  
    - Handles anomalous/outlier values in `price` and `msrp` by replacing values ≤1000 with group means.  
    - Fills missing numeric values with the mean.  
    - Encodes `transmission_from_vin` as a binary feature.  
    - Visualizes the distribution of transmissions via a pie chart.  
    - Creates a new feature `vehicle_age` (current_year - `model_year`).  
    - Processes `listing_first_date` to extract `year`, `month`, and `day`.  
    - Returns the cleaned DataFrame.  

  - **`save_preprocessed_data(output_file)`**  
    - Saves the preprocessed DataFrame to a CSV file.  

  - **`prepare_data()`**  
    - Splits the processed DataFrame into features (`X`) and target (`days_on_market`).  

### ✅ **Notable Design Decisions**
- **Outlier Replacement:**  
  Low `price` and `msrp` values are replaced with group means.  
- **Feature Engineering:**  
  Additional features such as `vehicle_age` and date components are created.  
- **Data Integrity:**  
  Extensive logging and duplicate/missing value checks ensure high-quality input data.  

---

## 2. **`train.py`**  

### **Purpose**
Trains two models (Ridge Regression and Linear Regression) using hyperparameter tuning and cross-validation.

### **ModelTrainer Class**

- **Attributes:**
  - `preprocessed_file (str)`: Path to the preprocessed CSV data.  
  - `model_output_path_v1` & `model_output_path_v2 (str)`: Paths to save the trained models.  
  - `test_cases_path (str)`: Directory to save test splits.  
  - Train/test splits (`X_train`, `X_test`, `y_train`, `y_test`).  
  - `best_model_v1` & `best_model_v2`: The tuned models.  

- **Methods:**
  - **`load_data()`**  
    - Loads preprocessed data.  

  - **`prepare_dataset()`**  
    - Splits data into features and target, then performs an 80/20 train/test split.  

  - **`build_pipeline(regressor_class)`**  
    - Creates a pipeline combining numeric (imputation, scaling) and categorical (one-hot encoding) transformations.  
    - Appends the specified regressor (Ridge or LinearRegression).  

  - **`train_and_save_model()`**  
    - Uses `RandomizedSearchCV` for hyperparameter tuning.  
    - Logs parameters and metrics with MLflow.  
    - Evaluates the model on test data (MSE, RMSE, R²).  
    - Saves the best model using `joblib.dump`.  

  - **`train()`**  
    - Trains both models:
      - **v1 (Ridge Regression):** Uses L2 regularization to mitigate multicollinearity.  
      - **v2 (Linear Regression):** Serves as a baseline model.  
    - Saves test datasets for future use.  

### ✅ **Notable Design Decisions**
- **Model Diversity:**  
  Using both Ridge and Linear Regression allows comparative analysis.  
- **Efficient Tuning:**  
  RandomizedSearchCV is used to efficiently search hyperparameter space.  
- **Pipeline Consistency:**  
  Ensures identical preprocessing for training and test data.  

---

## 3. **`predict.py` and `predict_api.py`**  

### **Purpose**
Loads the trained models and generates predictions on unseen data. Predictions can be run as a batch process or via a REST API for real-time inference.

### **REST API – `predict_api.py`**  
- **Endpoints:**
  - **Home (`/CMPT-2500_PROJECT_home`)** – Provides an overview of the API and expected JSON payload format.  
  - **Health (`/CMPT-2500_PROJECT_health_status`)** – Confirms that the API is running.  
  - **Predict v1 (`/v1/predict1`)** – Uses the Ridge Regression model to generate predictions on preprocessed data.  
  - **Predict v2 (`/v2/predict1`)** – Uses the Linear Regression model to generate predictions.  

---

## 4. **Docker Setup**  

### **Dockerfile**  
Defines the environment for the Flask-based prediction API container:
```dockerfile
FROM python:3.10-slim

WORKDIR /app

COPY requirements.txt requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

COPY . .
RUN mkdir -p Data/raw/processed

ENV PYTHONPATH=/app
ENV FLASK_APP=predict_api.py

EXPOSE 9000

CMD ["python", "predict_api.py"]
