Go_Auto Prediction API

Overview
This Flask-based REST API serves machine learning models for predicting vehicle time-on-market (in days) based on features such as mileage, MSRP, price change count, dealer attributes, and more.

It includes:

Two model versions for predictions: Ridge Regression and Linear Regression

Flask API endpoints

Health and home endpoints

Monitoring enabled with Prometheus & Grafana

| *Service*       | *Container Port Mapping* | *Description*                   |
|-------------------|----------------------------|-----------------------------------|
| ML App (v1)       | 5001:5000                  | Model v1 Flask server             |
| Prometheus        | 9090:9090                  | Monitoring metrics database       |
| Grafana           | 3000:3000                  | Visualization dashboard           |
| API App           | 8002:8002, 9000:9000       | REST API container (Flask)        |

> You can test the API locally via: http://127.0.0.1:9000


Available Endpoints

| *Method* | *Endpoint*               | *Description*                             |
|------------|----------------------------|---------------------------------------------|
| GET      | /Go_Auto_home            | Provides API description and usage          |
| GET      | /Go_Auto_health_status   | Confirms API is operational                 |
| GET      | /v1/predict1             | Ridge Regression prediction (best model)    |
| GET      | /v2/predict1             | Linear Regression prediction (baseline)     |

1. Home Endpoint
Endpoint: /Go_Auto_home

Method: GET

Purpose: Shows API purpose, routes, and input format.

curl -X GET http://127.0.0.1:9000/Go_Auto_home

Sample Response: 
{
  "message": "Welcome to the Go_Auto Prediction API.",
  "description": "This API predicts days-on-market using two ML models.",
  "endpoints": {
    "/v1/predict1": "Ridge model (v1)",
    "/v2/predict1": "Linear Regression model (v2)",
    "/Go_Auto_health_status": "API health check"
  }
}

2. Health Check
Endpoint: /Go_Auto_health_status

Method: GET

Purpose: Checks if API and models are ready.

curl -X GET http://127.0.0.1:9000/Go_Auto_health_status

Sample Response:
{
  "status": "Go_Auto API is up and running!",
  "models_loaded": {
    "model_v1": true,
    "model_v2": true
  }
}

3. Prediction - Ridge Regression (Model v1)
Endpoint: /v1/predict1

Method: GET

Model Path: models/ridge_model_v1.pkl

Sample Response:
[
  25.31,
  36.09,
  18.44
]

4. Prediction - Linear Regression (Model v2)
Endpoint: /v2/predict1

Method: GET

Model Path: models/linear_model_v2.pkl

Sample Response:
[
  22.33,
  31.04,

  20.51
]

6. How to Run Locally
# Clone your project
git clone https://github.com/https://github.com/Rohit222004/CMPT-2500-PROJECT.git

# Install dependencies
pip install -r requirements.txt

# Start API server
python src/predict_api.py

How to Run Prometheus & Grafana using Docker

Step 1: Run All Containers
docker-compose up -d

This will spin up:

The prediction API

Prometheus (at http://localhost:9090)

Grafana (at http://localhost:3000)

Access the Monitoring Tools

Tool | URL | Login Credentials (if needed)
Prometheus | http://localhost:9090 | N/A
Grafana | http://localhost:3000 | admin / admin (default)

You can:

Query real-time metrics in Prometheus

View dashboards and alerts in Grafana